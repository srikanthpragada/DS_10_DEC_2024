





# Importing required packages
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style='white')





train = pd.read_csv("final_train.csv")


X = train.drop(columns=['LoanStatus'])
y = train.LoanStatus


X = pd.get_dummies(X)  # One Hot Encoding 


X.columns





from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)





from sklearn.tree import export_text
from sklearn.ensemble import RandomForestClassifier


model = RandomForestClassifier(n_estimators=3, max_depth=3, random_state=10)
model.fit(X_train,y_train)


model.score(X_train,y_train)


y_pred = model.predict(X_test)


accuracy_score(y_test,y_pred)


# Print internal decision trees
for count, tree in enumerate(model.estimators_):
      # Print tree for each classifier 
      tree_rules = export_text(tree, feature_names =  list(X_train.columns))
      print("Tree : ",count + 1)
      print(tree_rules)      





from sklearn.ensemble import GradientBoostingClassifier


model = GradientBoostingClassifier(n_estimators=10, max_depth=3)
model.fit(X_train,y_train)


model.score(X_train,y_train)


y_pred = model.predict(X_test)


accuracy_score(y_test,y_pred)


errors = {}
tree_counts = [3,4, 5,8,10,15,20]
for count in tree_counts:
    model = GradientBoostingClassifier(n_estimators=count)
    model.fit(X_train,y_train)
    y_pred = model.predict(X_test)
    score = accuracy_score(y_test,y_pred)
    errors[count] = 1 - score # Error    


errors


# Draw a graph to show error rate and no. of trees
import matplotlib.pyplot as plt


plt.plot(list(errors.keys()), list(errors.values()))
plt.xlabel("No. of Trees")
plt.ylabel("Error")





from sklearn.ensemble import StackingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC


estimators = [
    ('lr',  LogisticRegression()),
    ('knn', KNeighborsClassifier(n_neighbors=5, n_jobs=1)),
    ('svc', SVC()),
]


clf = StackingClassifier(estimators=estimators, final_estimator=GaussianNB())


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=1)


from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
X_train_scaled = ss.fit_transform(X_train)


X_test_scaled = ss.transform(X_test)


clf.fit(X_train_scaled, y_train)


clf.score(X_test_scaled, y_test)


clf.__dict__



