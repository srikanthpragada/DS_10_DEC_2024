from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer


corpus = [
     'This is the first document.',
     'This document is the second document.',
     'And this is the third one.',
     'Is this the first document?',
]








cv = CountVectorizer()
X = cv.fit_transform(corpus)


X





print(cv.get_feature_names_out())


X.shape


type(X)


print(X.toarray())  # Convert sparse matrix to dense matrix (ndarray)








tf = TfidfTransformer()
XT = tf.fit_transform(X)
XT.shape


XT.toarray()





vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(corpus)


print(vectorizer.get_feature_names_out())


print(X.shape)


X.toarray()


vectorizer = TfidfVectorizer(ngram_range=(1, 2))
X = vectorizer.fit_transform(corpus)


X.shape


print(vectorizer.get_feature_names_out())


X


X.toarray()



